@article{Sandry,
author = {Sandryhaila, Aliaksei},
file = {:C$\backslash$:/Users/Cristina/Documents/Losanna/Thesis/SECT{\_}1 examples2.pdf:pdf},
number = {September},
pages = {80--90},
title = {{Signal Processing}},
year = {2014}
}

@article{Shuman2013,
abstract = {In applications such as social, energy, transportation, sensor, and neuronal networks, high-dimensional data naturally reside on the vertices of weighted graphs. The emerging field of signal processing on graphs merges algebraic and spectral graph theoretic concepts with computational harmonic analysis to process such signals on graphs. In this tutorial overview, we outline the main challenges of the area, discuss different ways to define graph spectral domains, which are the analogues to the classical frequency domain, and highlight the importance of incorporating the irregular structures of graph data domains when processing signals on graphs. We then review methods to generalize fundamental operations such as filtering, translation, modulation, dilation, and downsampling to the graph setting, and survey the localized, multiscale transforms that have been proposed to efficiently extract information from high-dimensional data on graphs. We conclude with a brief discussion of open issues and possible extensions.},
archivePrefix = {arXiv},
arxivId = {1211.0053},
author = {Shuman, David I. and Narang, Sunil K. and Frossard, Pascal and Ortega, Antonio and Vandergheynst, Pierre},
doi = {10.1109/MSP.2012.2235192},
eprint = {1211.0053},
file = {:C$\backslash$:/Users/Cristina/Documents/Losanna/Thesis/Paper 1.pdf:pdf},
isbn = {1053-5888 VO - 30},
issn = {10535888},
journal = {IEEE Signal Processing Magazine},
number = {3},
pages = {83--98},
pmid = {6494675},
title = {{The emerging field of signal processing on graphs: Extending high-dimensional data analysis to networks and other irregular domains}},
volume = {30},
year = {2013}
}

@article{Ortega2017,
abstract = {Research in Graph Signal Processing (GSP) aims to develop tools for processing data defined on irregular graph domains. In this paper we first provide an overview of core ideas in GSP and their connection to conventional digital signal processing. We then summarize recent developments in developing basic GSP tools, including methods for sampling, filtering or graph learning. Next, we review progress in several application areas using GSP, including processing and analysis of sensor network data, biological data, and applications to image processing and machine learning. We finish by providing a brief historical perspective to highlight how concepts recently developed in GSP build on top of prior research in other areas.},
archivePrefix = {arXiv},
arxivId = {1712.00468},
author = {Ortega, Antonio and Frossard, Pascal and Kova{\v{c}}evi{\'{c}}, Jelena and Moura, Jos{\'{e}} M. F. and Vandergheynst, Pierre},
doi = {10.1109/JPROC.2018.2820126},
eprint = {1712.00468},
file = {:C$\backslash$:/Users/Cristina/Documents/Losanna/Thesis/Graph signal processing.pdf:pdf},
issn = {0018-9219},
pages = {1--18},
title = {{Graph Signal Processing: Overview, Challenges and Applications}},
url = {http://arxiv.org/abs/1712.00468},
year = {2017}
}

@article{Tosic2011,
abstract = {We describe methods for learning dictionaries that are appropriate for the representation of given classes of signals and multisensor data. We further show that dimensionality reduction based on dictionary representation can be extended to address specific tasks such as data analy sis or classification when the learning includes a class separability criteria in the objective function. The benefits of dictionary learning clearly show that a proper understanding of causes underlying the sensed world is key to task-specific representation of relevant information in high-dimensional data sets.},
archivePrefix = {arXiv},
arxivId = {arXiv:1402.1515v1},
author = {Tosic, Ivana and Frossard, Pascal},
doi = {10.1109/MSP.2010.939537},
eprint = {arXiv:1402.1515v1},
file = {:C$\backslash$:/Users/Cristina/Documents/Losanna/Thesis/Disctionary learning.pdf:pdf},
isbn = {1053-5888},
issn = {1053-5888},
journal = {Signal Processing Magazine, IEEE},
keywords = {dictionaries,dictionary learning,engineering education,high dimensional data sets,multisensor data,objective function,relevant information,task-specific representation},
number = {2},
pages = {27--38},
title = {{Dictionary Learning, What is the right representation for my signal?}},
volume = {28},
year = {2011}
}

@article{Rubinstein2010,
abstract = {Sparse and redundant representation modeling of data assumes an ability to describe signals as linear combina- tions of a few atoms from a pre-specified dictionary. As such, the choice of the dictionary that sparsifies the signals is crucial for the success of this model. In general, the choice of a proper dictionary can be done using one of two ways: i) building a sparsifying dictionary based on a mathematical model of the data, or ii) learning a dictionary to perform best on a training set. In this paper we describe the evolution of these two paradigms. As manifestations of the first approach, we cover topics such as wavelets, wavelet packets, contourlets, and curvelets, all aiming to exploit 1-Dand 2-Dmathematicalmodels for constructing effective dictionaries for signals and images. Dictionary learning takes a different route, attaching the dictionary to a set of examples it is supposed to serve. From the seminal work of Field and Olshausen, through the MOD, the K-SVD, the Generalized PCA and others, this paper surveys the various options such training has to offer, up to themost recent contributions and structures.},
author = {Rubinstein, By Ron and Bruckstein, Alfred M and Elad, Michael},
doi = {10.1109/JPROC.2010.2040551},
file = {:C$\backslash$:/Users/Cristina/Documents/Losanna/Thesis/IEEE{\_}Proc{\_}Dictionary.pdf:pdf},
issn = {0018-9219, 1558-2256},
keywords = {approximation,dictionary learning,harmonic analysis,signal,signal representation,sparse,sparse coding},
number = {6},
pages = {1045--1057},
title = {{Dictionaries for Sparse Representation Modeling.pdf}},
volume = {98},
year = {2010}
}
